# Interactive Multimodal Document Querying System with LLMs  

This project leverages **Large Language Models (LLMs)** to build an interactive system that allows users to query data from multimodal documents, such as PDFs, images, audio, and video files. Designed with **Streamlit**, it provides a simple and user-friendly interface to extract and analyze insights from complex datasets, enabling smarter and faster decision-making across industries.  

---

## 🚀 Features  

### 🔍 Multimodal Document Search  
- Supports PDFs, images, audio, and video files.  
- Extracts text, images, and context from diverse file formats.  

### 🤖 AI-Powered Querying  
- Uses **Google Gemini LLMs** for advanced natural language understanding.  
- Customizable response parameters like temperature, Top-P, and token limits.  

### 🛠️ Configurable Settings  
- Fine-tune model behaviors for creative, precise, or contextual results.  
- Adjust output limits for tailored use cases.  

### 📊 Real-World Applications  
- **Pharma**: Clinical trial data analysis, compliance checks, patient data integration.  
- **Hospitality**: Maintenance logs analysis, guest sentiment insights, supply chain management.  
- **Enterprise**: Knowledge transfer, project-specific insights, and collaboration across teams.  

---

## 🏗️ Tech Stack  

- **Streamlit**: For building an interactive user interface.  
- **Google Gemini LLMs**: For generative AI-based querying and insights.  
- **PyPDF & FitZ**: For PDF text extraction and image rendering.  
- **Python**: For backend logic and file processing.  
- **dotenv**: For secure API key management.  

---

## 📚 How to Use  

### 1. Setup  
1. Clone this repository:  
   ```bash  
   git clone https://github.com/AjayAJ2000/Interactive_document_querying_system_using_llms.git
   cd <repository_directory>  
